{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_path = \"C:/Users/Brian/Desktop/Projects/ai_driver_assistant_cv/Models/Traffic_Sign_model_v1/Road_Sign_Detection_saved_model/Road_Sign_Detection_v1.tflite\"\n",
    "labels_path = \"C:/Users/Brian/Desktop/Projects/ai_driver_assistant_cv/Models/Traffic_Sign_model_v1/traffic_sign_labels.txt\"\n",
    "save_path = \"C:/Users/Brian/Desktop/Projects/ai_driver_assistant_cv/Models/Traffic_Sign_model_v1/Road_Sign_Detection_saved_model/Road_Sign_Detection_updated.tflite\"\n",
    "\n",
    "INPUT_NORM_MEAN = 127.5\n",
    "INPUT_NORM_STD = 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"Traffic Sign V1 Object Detection\"\n",
    "model_meta.description = (\"Identify Road traffic signs with YOLOv8n model as base.\")\n",
    "model_meta.version = \"v1\"\n",
    "model_meta.author = \"Brian Mortimer\"\n",
    "model_meta.license = (\"Apache License. Version 2.0 \"\n",
    "                      \"http://www.apache.org/licenses/LICENSE-2.0.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates input info.\n",
    "input_meta = _metadata_fb.TensorMetadataT()\n",
    "\n",
    "# Creates output info.\n",
    "output_meta = _metadata_fb.TensorMetadataT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_meta.name = \"image\"\n",
    "input_meta.description = (\n",
    "    \"Input image to perform object detection. The expected image is {0} x {1}, with \"\n",
    "    \"three channels (red, blue, and green) per pixel. Each value in the \"\n",
    "    \"tensor is a single byte between 0 and 255.\".format(640, 640))\n",
    "input_meta.content = _metadata_fb.ContentT()\n",
    "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "input_meta.content.contentProperties.colorSpace = (\n",
    "    _metadata_fb.ColorSpaceType.RGB)\n",
    "input_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.ImageProperties)\n",
    "input_normalization = _metadata_fb.ProcessUnitT()\n",
    "input_normalization.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
    "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "input_normalization.options.mean = [INPUT_NORM_MEAN]\n",
    "input_normalization.options.std = [INPUT_NORM_STD]\n",
    "input_meta.processUnits = [input_normalization]\n",
    "input_stats = _metadata_fb.StatsT()\n",
    "input_stats.max = [255]\n",
    "input_stats.min = [0]\n",
    "input_meta.stats = input_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates output info.\n",
    "output_meta = _metadata_fb.TensorMetadataT()\n",
    "output_meta.name = \"probability\"\n",
    "output_meta.description = \"Probabilities of the 1001 labels respectively.\"\n",
    "output_meta.content = _metadata_fb.ContentT()\n",
    "output_meta.content.content_properties = _metadata_fb.FeaturePropertiesT()\n",
    "output_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_stats = _metadata_fb.StatsT()\n",
    "output_stats.max = [1.0]\n",
    "output_stats.min = [0.0]\n",
    "output_meta.stats = output_stats\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = labels_path\n",
    "label_file.description = \"Labels for objects that the model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_AXIS_LABELS\n",
    "output_meta.associatedFiles = [label_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates outputs info.\n",
    "output_location_meta = _metadata_fb.TensorMetadataT()\n",
    "output_location_meta.name = \"location\"\n",
    "output_location_meta.description = \"The locations of the detected boxes.\"\n",
    "output_location_meta.content = _metadata_fb.ContentT()\n",
    "output_location_meta.content.contentPropertiesType = (_metadata_fb.ContentProperties.BoundingBoxProperties)\n",
    "output_location_meta.content.contentProperties = (_metadata_fb.BoundingBoxPropertiesT())\n",
    "output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
    "output_location_meta.content.contentProperties.type = (_metadata_fb.BoundingBoxType.BOUNDARIES)\n",
    "output_location_meta.content.contentProperties.coordinateType = (_metadata_fb.CoordinateType.RATIO)\n",
    "output_location_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_location_meta.content.range.min = 2\n",
    "output_location_meta.content.range.max = 2\n",
    "\n",
    "output_class_meta = _metadata_fb.TensorMetadataT()\n",
    "output_class_meta.name = \"category\"\n",
    "output_class_meta.description = \"The categories of the detected boxes.\"\n",
    "output_class_meta.content = _metadata_fb.ContentT()\n",
    "output_class_meta.content.contentPropertiesType = (_metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_class_meta.content.contentProperties = (_metadata_fb.FeaturePropertiesT())\n",
    "output_class_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_class_meta.content.range.min = 2\n",
    "output_class_meta.content.range.max = 2\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = labels_path\n",
    "label_file.description = \"Label of objects that this model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_VALUE_LABELS\n",
    "output_class_meta.associatedFiles = [label_file]\n",
    "\n",
    "output_score_meta = _metadata_fb.TensorMetadataT()\n",
    "output_score_meta.name = \"score\"\n",
    "output_score_meta.description = \"The scores of the detected boxes.\"\n",
    "output_score_meta.content = _metadata_fb.ContentT()\n",
    "output_score_meta.content.contentPropertiesType = (_metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_score_meta.content.contentProperties = (_metadata_fb.FeaturePropertiesT())\n",
    "output_score_meta.content.range = _metadata_fb.ValueRangeT()\n",
    "output_score_meta.content.range.min = 2\n",
    "output_score_meta.content.range.max = 2\n",
    "\n",
    "output_number_meta = _metadata_fb.TensorMetadataT()\n",
    "output_number_meta.name = \"number of detections\"\n",
    "output_number_meta.description = \"The number of the detected boxes.\"\n",
    "output_number_meta.content = _metadata_fb.ContentT()\n",
    "output_number_meta.content.contentPropertiesType = (_metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_number_meta.content.contentProperties = (_metadata_fb.FeaturePropertiesT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates subgraph info.\n",
    "subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "subgraph.inputTensorMetadata = [input_meta]\n",
    "subgraph.outputTensorMetadata = [output_location_meta, output_class_meta, output_score_meta, output_number_meta]\n",
    "model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of output tensors (1) should match the number of output tensor metadata (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m populator \u001b[38;5;241m=\u001b[39m _metadata\u001b[38;5;241m.\u001b[39mMetadataPopulator\u001b[38;5;241m.\u001b[39mwith_model_file(model_path)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpopulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_metadata_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_buf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m populator\u001b[38;5;241m.\u001b[39mload_associated_files([labels_path])\n\u001b[0;32m      4\u001b[0m populator\u001b[38;5;241m.\u001b[39mpopulate()\n",
      "File \u001b[1;32mc:\\Users\\Brian\\anaconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow_lite_support\\metadata\\python\\metadata.py:302\u001b[0m, in \u001b[0;36mMetadataPopulator.load_metadata_buffer\u001b[1;34m(self, metadata_buf)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m metadata_buf:\n\u001b[0;32m    300\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe metadata to be populated is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_buf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# Gets the minimum metadata parser version of the metadata_buf.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m min_version \u001b[38;5;241m=\u001b[39m _pywrap_metadata_version\u001b[38;5;241m.\u001b[39mGetMinimumMetadataParserVersion(\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mbytes\u001b[39m(metadata_buf))\n",
      "File \u001b[1;32mc:\\Users\\Brian\\anaconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow_lite_support\\metadata\\python\\metadata.py:639\u001b[0m, in \u001b[0;36mMetadataPopulator._validate_metadata\u001b[1;34m(self, metadata_buf)\u001b[0m\n\u001b[0;32m    636\u001b[0m num_output_meta \u001b[38;5;241m=\u001b[39m model_meta\u001b[38;5;241m.\u001b[39mSubgraphMetadata(\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mOutputTensorMetadataLength()\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_output_tensors \u001b[38;5;241m!=\u001b[39m num_output_meta:\n\u001b[1;32m--> 639\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    640\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of output tensors (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m) should match the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    641\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput tensor metadata (\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(num_output_tensors,\n\u001b[0;32m    642\u001b[0m                                             num_output_meta))\n",
      "\u001b[1;31mValueError\u001b[0m: The number of output tensors (1) should match the number of output tensor metadata (4)"
     ]
    }
   ],
   "source": [
    "populator = _metadata.MetadataPopulator.with_model_file(model_path)\n",
    "populator.load_metadata_buffer(metadata_buf)\n",
    "populator.load_associated_files([labels_path])\n",
    "populator.populate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflite1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
